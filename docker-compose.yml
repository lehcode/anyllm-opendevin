version: "3.8"
services:
  # Devin Out-of-The-Box Agent Service
  app:
    container_name: devin-app
    hostname: oppendevin
    image: oppendevin-cuda_11.3.1-conda:latest
    build:
      dockerfile: docker/devin/app/Dockerfile
      args:
        litellm_port: ${LITELLM_PORT:?}
        jupyter_port: ${JUPYTER_PORT:?}
        debug: ${DEBUG:-}
        conda_dir: ${CONDA_PREFIX}
        nvidia_utils_driver: 550
    env_file:
      - ./.env
      - docker/devin/app/.env
    command: /docker-entrypoint.sh
    depends_on:
      - litellm
      - mitm
      - postgres
      - redis
    networks:
      opendevin-net:
        ipv4_address: 172.28.0.222
    volumes:
      - ./workspace:${WORKSPACE_DIR:?}
# Uncomment mounts if need for development
# By default files are simply copied inside container on build
#      - ./requirements.txt:${APP_DIR:?}/
#      - ./Makefile:${APP_DIR:?}/
#      - ./:${APP_DIR:?}/
      - app_root_dir_vol:/root
      - pip_cache_vol:/root/.cache/pip:tmpfs=4G
      - conda_cache_vol:${CONDA_PREFIX:?}/conda/.pkgs:tmpfs=4G
      - ./docker/devin/app/.condarc:${CONDA_PREFIX:?}/.condarc
      - conda_env_vol:${CONDA_PREFIX:?}/envs/${VENV_NAME:?}
      - ./docker/env_debug.sh:/root/devin/scripts/env_debug
    working_dir: ${APP_DIR}
    tmpfs:
      - /run
      - /tmp
      - /var/run
    ports:
      - "${APP_HTTP_PORT}:${APP_HTTP_PORT}"
      - "${APP_HTTPS_PORT}:${APP_HTTPS_PORT}"
      - "${JUPYTER_PORT:?}:${JUPYTER_PORT:?}"
    tty: true
    stdin_open: true
    restart: no
    deploy:
      resources:
        reservations:
          devices:
            - driver: "nvidia"
              count: 1
              capabilities: [ "gpu" ]

  # MemGPT üè¨
#  memgpt:
#    container_name: devin-memgpt
#    hostname: devin-memgpt
#    build:
#      dockerfile: docker/memgpt/Dockerfile
#      args:
##        litellm_port: ${LITELLM_PORT:?}
##        jupyter_port: ${JUPYTER_PORT:?}
#        debug: ${DEBUG:?}
#        timezone: ${TIMEZONE:?}
#        litellm_port: ${LITELLM_PORT:?}
#        memgpt_config_file: /etc/.memgpt/memgpt.conf
#        conda_prefix: ${CONDA_PREFIX:?}
#        conda_pkgs_dirs: ${CONDA_PREFIX:?}/.pkgs
#    env_file:
#      - .env
#      - docker/memgpt/.env
#    environment:
#      PGVECTOR_TEST_DB_URL: postgresql+pg8000://memgpt:memgpt@localhost:8888/memgpt_memory
#    working_dir: /root
#    volumes:
#      - ${HOST_MODELS_DIR:?}:/root/.ollama/models
#      - pip_cache_vol:/root/.cache/pip:tmpfs=4G
#      - conda_cache_vol:/root/conda/.pkgs:tmpfs=4G
#      - conda_env_vol:/root/conda/envs/${VENV_NAME:?}:tmpfs=4G
#      - ./docker/memgpt/.condarc:/root/.condarc
#      - ./docker/memgpt/config.conf:/root/.memgpt/memgpt.conf
#    #      - ./.mitmproxy/mitmproxy-ca.pem:/usr/local/share/ca-certificates/mitmproxy-ca.crt
#    tmpfs:
#      - /tmp
#      - /var/tmp
#    depends_on:
#      - ollama
#      - litellm
###      - proxy
#    networks:
#      - opendevin-net
#    tty: true
#    stdin_open: true
#    entrypoint: /usr/local/bin/launcher
#    deploy:
#      resources:
#        reservations:
#          devices:
#            - driver: "nvidia"
#              count: 1
#              capabilities: [ "gpu" ]

  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: litellm_backend
    command: "--config /etc/config.yaml --port ${LITELLM_PORT} --num_workers 8 --detailed_debug"
    environment:
      LITELLM_DEFAULT_MODEL: ${LITELLM_DEFAULT_MODEL:?}
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:${POSTGRES_CONTAINER_PORT}/${POSTGRES_DB}
    ports:
      - "${LITELLM_PORT}:4000"
    volumes:
      - ./docker/litellm/config.yaml:/etc/config.yaml
      - pip_cache_vol:/root/.cache/pip
      - ./docker/env_debug.sh:/usr/local/bin/env_debug
    depends_on:
      - redis
      - postgres
      - ollama
    networks:
      - opendevin-net
    healthcheck:
      test: [ "CMD", "litellm", "--health" ]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 2m
    tmpfs:
      - /run
      - /var/run
      - /tmp
      - /var/tmp

  redis:
    image: redis/redis-stack:latest
    container_name: redis-stack-server
    env_file:
      - .env
      - docker/redis/redis.env
    ports:
      - "0.0.0.0:${REDIS_SERVER_PORT}:6379"
      - "0.0.0.0:${REDIS_INSIGHT_PORT}:8001"
    volumes:
      - redis_data:${REDIS_DATA:-/data}
    networks:
      - opendevin-net

  postgres:
    image: postgres:latest
    container_name: db-postgres
    env_file:
      - .env
      - docker/postgres/postgres.env
    volumes:
      - posgtres_data:${POSTGRES_DATA:-/var/lib/postgres}
    ports:
      - "${POSTGRES_HOST_PORT}:${POSTGRES_CONTAINER_PORT}"
    tmpfs:
      - /var/run:size=1m
      - /tmp
    networks:
      - opendevin-net

  # Ollama service
  ollama:
    image: ollama/ollama
    container_name: ollama-service
    hostname: ollama
    platform: linux/amd64
    env_file:
      - .env
      - docker/ollama/ollama.env
    tty: false
    ports:
      - "22434:11434"
    volumes:
      - ${HOST_MODELS_DIR:?}:/root/.ollama/models
      - pip_cache_vol:/root/.cache/pip
    deploy:
      resources:
        reservations:
          devices:
            - driver: "nvidia"
              count: 1
              capabilities: [ "gpu" ]

    networks:
      - opendevin-net
    tmpfs:
      - /run
      - /var/run
      - /tmp
      - /var/tmp

  mitm:
    build:
      dockerfile: ./docker/mitmproxy/Dockerfile
      args:
        version: ${MITMPROXY_VERSION:?}
        proxy_wheel: mitmproxy-${MITMPROXY_VERSION:?}-py3-none-any.whl
        mitmproxy_dir: ${MITMPROXY_DIR:?}
        uid: 1000
        gid: 1000
    container_name: mitmproxy
    command: "mitmweb --web-host 0.0.0.0 --web-port 8081 --mode reverse:http://ollama:11434@44444 --verbose --anticache --anticomp"
    networks:
      - opendevin-net
    volumes:
      - ./.mitmproxy:${MITMPROXY_DIR:?}
    tty: true
    stdin_open: true
    ports:
      - "0.0.0.0:8081:8081"
    tmpfs:
      - /run
      - /var/run
      - /tmp
      - /var/tmp

  # UI service
  ui:
    container_name: devin-ui
    build:
      dockerfile: docker/devin/ui/nginx/Dockerfile
      args:
        ui_dir: ${UI_DIR:-/var/www/od_ui}
        node_version: ${NODE_VERSION:?}
        node_env: ${NODE_ENV:-production}
        debug: ${DEBUG:?}
    env_file: docker/devin/ui/.env
    environment:
      BACKEND_HOST: 172.28.111.5:3000
      FRONTEND_PORT: 3001
    networks:
      - opendevin-net
    ports:
      - "18888:18888"
      - "8088:8088"
      - "3001:3001"
      - "8443:8443"
    depends_on:
      - app
    tty: true
    working_dir: ${UI_DIR:-/var/www/od_ui}
    volumes:
      - ./docker/devin/ui/nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./frontend/dist/:/var/www/app/dist/

networks:
  opendevin-net:
    ipam:
      driver: default
      config:
        - subnet: 172.28.0.0/16
          gateway: 172.28.111.1

volumes:
  app_root_dir_vol:
  posgtres_data:
  redis_data:
  pip_cache_vol:
  conda_cache_vol:
  conda_env_vol:
